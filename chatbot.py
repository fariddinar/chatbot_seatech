import os
import json
import streamlit as st
import chromadb
from langchain.prompts import PromptTemplate
from langchain_groq import ChatGroq
import sqlite3
from dotenv import load_dotenv


# ğŸ”‘ Configuration de l'API Groq (Ã  remplacer par votre clÃ©)
# Charger les variables d'environnement depuis .env
load_dotenv()

# RÃ©cupÃ©rer la clÃ© API
API_KEY = os.getenv("API_KEY")

if not API_KEY:
    raise ValueError("La clÃ© API GROQ_API_KEY n'est pas dÃ©finie.")

# ğŸŸ¢ Initialisation de ChromaDB
chroma_client = chromadb.Client()
collection = chroma_client.get_or_create_collection(name="seatech_chunks")

# ğŸ“‚ Chargement des donnÃ©es JSON
def load_json(filename):
    with open(filename, "r", encoding="utf-8") as f:
        return json.load(f)

data = load_json("donnees_seatech.json")
chunks = [entry['markdown'] for entry in data]  # Assurez-vous que la clÃ© 'markdown' existe

# ğŸ”„ Ajout des documents Ã  ChromaDB
collection.upsert(
    documents=chunks,
    ids=[str(i) for i in range(len(chunks))]
)

# ğŸ“œ CrÃ©ation du modÃ¨le de rÃ©ponse
template = """
Tu es un assistant intelligent et utile. RÃ©ponds aux questions de l'utilisateur en franÃ§ais de maniÃ¨re claire et concise.

**Question de l'utilisateur :** {question}

ğŸ“Œ **Documents pertinents :**
{documents}

ğŸ’¡ **RÃ©ponse :**
"""

prompt = PromptTemplate(template=template, input_variables=["question", "documents"])
llm = ChatGroq(api_key=API_KEY, temperature=0, model="llama3-70b-8192")
chain = prompt | llm

# ğŸ¨ **Interface Streamlit**
st.set_page_config(page_title="Chatbot Seatech", page_icon="ğŸ’¬", layout="wide")

# ğŸ“Œ **En-tÃªte**
st.markdown("<h1 style='text-align: center; color: #0066cc;'>ğŸ”¹ Chatbot Seatech ğŸ”¹</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center;'>Posez votre question sur l'Ã©cole et obtenez une rÃ©ponse instantanÃ©e !</p>", unsafe_allow_html=True)

# ğŸ“ **Champ de saisie**
question = st.text_input("ğŸ’¬ Posez votre question ici :", placeholder="Exemple : Admission sur dossier")

if st.button("ğŸ” Rechercher"):
    if question:
        with st.spinner("ğŸ”„ Recherche en cours..."):
            # ğŸ” Interrogation de ChromaDB
            results = collection.query(query_texts=[question], n_results=3)
            retrieved_docs = "\n".join(results['documents'][0])

            # ğŸ”¥ GÃ©nÃ©ration de la rÃ©ponse avec LangChain
            response = chain.invoke({"question": question, "documents": retrieved_docs})

        # ğŸ“ **Affichage de la rÃ©ponse**
        st.markdown("### âœ¨ RÃ©ponse :")
        st.success(response.content)

        # ğŸ“š **Affichage des documents pertinents**
        with st.expander("ğŸ“‚ Documents similaires retrouvÃ©s"):
            for i, doc in enumerate(results['documents'][0]):
                st.write(f"**{i+1}.** {doc}")

    else:
        st.warning("âš ï¸ Veuillez entrer une question avant de rechercher.")

# ğŸ“Œ **Pied de page**
st.markdown("---")
st.markdown("<p style='text-align: center; color: grey;'>Â© 2025 Seatech AI | DÃ©veloppÃ© en Python</p>", unsafe_allow_html=True)
